{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import math\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import plotly.offline as py\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "import gc\n",
    "\n",
    "from sklearn import metrics\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "#NLP\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk import word_tokenize\n",
    "stop = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from nltk.stem.porter import PorterStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('Tweets_dataset/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('Tweets_dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7613"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x267208409c8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Missing Values\n",
    "sns.heatmap(data_train.isnull(),yticklabels = False,cbar = False,cmap = 'viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x26720929208>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Good Practice: Always check if data set is balance or imbalance.\n",
    "sns.set_style('whitegrid')\n",
    "sns.countplot(x='target',data=data_train,palette='RdBu_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\adeel\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning:\n",
      "\n",
      "Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10876, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.concat([data_train,data_test])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "corpus = []\n",
    "def tokenize(text):\n",
    "    \n",
    "    try: \n",
    "        #Removing urls\n",
    "        url_regex = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "        text = url_regex.sub(r'',text)\n",
    "        #Html Tags\n",
    "        HtmlTags_regex = re.compile(r'<.*?>')\n",
    "        text = HtmlTags_regex.sub(r'',text)\n",
    "        #remove emojis\n",
    "        emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "        text = emoji_pattern.sub(r'', text)\n",
    "        # remove punctuatio\n",
    "        regex = re.compile('[' +re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n]')\n",
    "        text = regex.sub(\" \", text)\n",
    "        \n",
    "        \n",
    "        #tokens_ = [word_tokenize(s) for s in sent_tokenize(text)]\n",
    "        #tokens_ = [lemmatizer.lemmatize(word) for word in tokens_ if word not in set(stopwords.words('english'))]\n",
    "        #tokens_ = [ps.stem(word) for word in tokens_ if not word in stopwords.words('english')]\n",
    "        #tokens = []\n",
    "        #for token_by_sent in tokens_:\n",
    "            #tokens += token_by_sent\n",
    "        #tokens = list(filter(lambda t: t.lower() not in stop, tokens))\n",
    "        #filtered_tokens = [w for w in tokens if re.search('[a-zA-Z]', w)]\n",
    "        #filtered_tokens = [w.lower() for w in filtered_tokens if len(w)>=3]\n",
    "        #corpus.append(filtered_tokens)\n",
    "        #return filtered_tokens\n",
    "        return text\n",
    "            \n",
    "    except TypeError as e: print(text,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].map(tokenize)\n",
    "#data_test['text'] = data_test['item_description'].map(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Our Deeds are the Reason of this  earthquake M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Forest fire near La Ronge Sask  Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>All residents asked to  shelter in place  are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>people receive  wildfires evacuation or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Just got sent this photo from Ruby  Alaska as ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location  target  \\\n",
       "0   1     NaN      NaN     1.0   \n",
       "1   4     NaN      NaN     1.0   \n",
       "2   5     NaN      NaN     1.0   \n",
       "3   6     NaN      NaN     1.0   \n",
       "4   7     NaN      NaN     1.0   \n",
       "\n",
       "                                                text  \n",
       "0  Our Deeds are the Reason of this  earthquake M...  \n",
       "1             Forest fire near La Ronge Sask  Canada  \n",
       "2  All residents asked to  shelter in place  are ...  \n",
       "3         people receive  wildfires evacuation or...  \n",
       "4  Just got sent this photo from Ruby  Alaska as ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyspellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker\n",
    "from tqdm import tqdm\n",
    "spell = SpellChecker()\n",
    "def correct_spellings(text):\n",
    "    corrected_text = []\n",
    "    misspelled_words = spell.unknown(text.split())\n",
    "    for word in text.split():\n",
    "        if word in misspelled_words:\n",
    "            corrected_text.append(spell.correction(word))\n",
    "        else:\n",
    "            corrected_text.append(word)\n",
    "    return \" \".join(corrected_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['text1']=df['text'].apply(lambda x : correct_spellings(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def create_corpus(df):\n",
    "    corpus=[]\n",
    "    for tweet in tqdm(df['text']):\n",
    "        words=[word.lower() for word in word_tokenize(tweet) if((word.isalpha()==1) & (word not in stop))]\n",
    "        corpus.append(words)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10876/10876 [00:01<00:00, 5770.32it/s]\n"
     ]
    }
   ],
   "source": [
    "corpus=create_corpus(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dict={}\n",
    "with open('glove/glove.6B.100d.txt',encoding=\"utf8\") as f: #,'r'\n",
    "    for line in f:\n",
    "        values=line.split()\n",
    "        word=values[0]\n",
    "        vectors=np.asarray(values[1:],'float32')\n",
    "        embedding_dict[word]=vectors\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "#from tqdm import tqdm\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding,LSTM,Dense,SpatialDropout1D\n",
    "from keras.initializers import Constant\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN=50\n",
    "tokenizer_obj=Tokenizer()\n",
    "tokenizer_obj.fit_on_texts(corpus)\n",
    "sequences=tokenizer_obj.texts_to_sequences(corpus)\n",
    "\n",
    "tweet_pad=pad_sequences(sequences,maxlen=MAX_LEN,truncating='post',padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 20200\n"
     ]
    }
   ],
   "source": [
    "word_index=tokenizer_obj.word_index\n",
    "print('Number of unique words:',len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 20200/20200 [00:00<00:00, 354604.49it/s]\n"
     ]
    }
   ],
   "source": [
    "num_words=len(word_index)+1\n",
    "embedding_matrix=np.zeros((num_words,100))\n",
    "\n",
    "for word,i in tqdm(word_index.items()):\n",
    "    if i > num_words:\n",
    "        continue\n",
    "    \n",
    "    emb_vec=embedding_dict.get(word)\n",
    "    if emb_vec is not None:\n",
    "        embedding_matrix[i]=emb_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "\n",
    "embedding=Embedding(num_words,100,embeddings_initializer=Constant(embedding_matrix),\n",
    "                   input_length=MAX_LEN,trainable=False)\n",
    "\n",
    "model.add(embedding)\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "optimzer=Adam(learning_rate=1e-5)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer=optimzer,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 50, 100)           2020100   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 50, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                42240     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 2,062,405\n",
      "Trainable params: 42,305\n",
      "Non-trainable params: 2,020,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=tweet_pad[:data_train.shape[0]]\n",
    "test=tweet_pad[data_train.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train (6471, 50)\n",
      "Shape of Validation  (1142, 50)\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(train,data_train['target'].values,test_size=0.15)\n",
    "print('Shape of train',X_train.shape)\n",
    "print(\"Shape of Validation \",X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6471 samples, validate on 1142 samples\n",
      "Epoch 1/15\n",
      " - 29s - loss: 0.6916 - accuracy: 0.5712 - val_loss: 0.6903 - val_accuracy: 0.5613\n",
      "Epoch 2/15\n",
      " - 26s - loss: 0.6845 - accuracy: 0.5724 - val_loss: 0.6666 - val_accuracy: 0.5657\n",
      "Epoch 3/15\n",
      " - 27s - loss: 0.6164 - accuracy: 0.6801 - val_loss: 0.5449 - val_accuracy: 0.7688\n",
      "Epoch 4/15\n",
      " - 26s - loss: 0.5852 - accuracy: 0.7200 - val_loss: 0.5258 - val_accuracy: 0.7706\n",
      "Epoch 5/15\n",
      " - 26s - loss: 0.5644 - accuracy: 0.7347 - val_loss: 0.5146 - val_accuracy: 0.7767\n",
      "Epoch 6/15\n",
      " - 26s - loss: 0.5630 - accuracy: 0.7374 - val_loss: 0.5075 - val_accuracy: 0.7802\n",
      "Epoch 7/15\n",
      " - 26s - loss: 0.5530 - accuracy: 0.7450 - val_loss: 0.5020 - val_accuracy: 0.7793\n",
      "Epoch 8/15\n",
      " - 26s - loss: 0.5497 - accuracy: 0.7535 - val_loss: 0.4980 - val_accuracy: 0.7846\n",
      "Epoch 9/15\n",
      " - 26s - loss: 0.5510 - accuracy: 0.7492 - val_loss: 0.4962 - val_accuracy: 0.7855\n",
      "Epoch 10/15\n",
      " - 26s - loss: 0.5382 - accuracy: 0.7594 - val_loss: 0.4924 - val_accuracy: 0.7890\n",
      "Epoch 11/15\n",
      " - 26s - loss: 0.5367 - accuracy: 0.7569 - val_loss: 0.4916 - val_accuracy: 0.7863\n",
      "Epoch 12/15\n",
      " - 26s - loss: 0.5376 - accuracy: 0.7582 - val_loss: 0.4890 - val_accuracy: 0.7863\n",
      "Epoch 13/15\n",
      " - 26s - loss: 0.5386 - accuracy: 0.7541 - val_loss: 0.4889 - val_accuracy: 0.7872\n",
      "Epoch 14/15\n",
      " - 26s - loss: 0.5347 - accuracy: 0.7636 - val_loss: 0.4862 - val_accuracy: 0.7907\n",
      "Epoch 15/15\n",
      " - 26s - loss: 0.5384 - accuracy: 0.7557 - val_loss: 0.4846 - val_accuracy: 0.7907\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train,y_train,batch_size=4,epochs=15,validation_data=(X_test,y_test),verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub=pd.read_csv('Tweets_dataset/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre=model.predict(test)\n",
    "y_pre=np.round(y_pre).astype(int).reshape(3263)\n",
    "sub=pd.DataFrame({'id':sample_sub['id'].values.tolist(),'target':y_pre})\n",
    "sub.to_csv('Tweets_dataset/submission_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       1\n",
       "1   2       1\n",
       "2   3       1\n",
       "3   9       1\n",
       "4  11       1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
